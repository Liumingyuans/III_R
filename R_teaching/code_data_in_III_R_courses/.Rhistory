ytest = sample(c(-1, 1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,] + 1
testdat = data.frame(x = xtest, y = as.factor(ytest))
ypred = predict(bestmod, testdat)
table(predict=ypred, truth=testdat$y)
# SVM: Case study of letterdata.csv
letters <- read.csv("c://R/r.data/letterdata.csv")
str(letters)
letters_train <- letters[1:16000, ]
letters_test  <- letters[16001:20000, ]
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = "vanilladot")
letter_classifier
letter_predictions <- predict(letter_classifier, letters_test)
head(letter_predictions)
table(letter_predictions, letters_test$letter)[1:5,1:5]
agreement <- letter_predictions == letters_test$letter
table(agreement)
prop.table(table(agreement))
letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = "rbfdot")
letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)
agreement_rbf <- letter_predictions_rbf == letters_test$letter
table(agreement_rbf)
prop.table(table(agreement_rbf))
?poisson
rpois(10,3)
hist(rpois(10,3))
?rpois
a = rpois(100,3)
table(a)
a = rpois(10000,3)
table(a)
a/10000
a = rpois(10000,3)
table(a)
table(a)/10000
a = rpois(100000,3)
table(a)/100000
n = 100000
a = rpois(n,3)
table(a)/n
n = 1000000
a = rpois(n,3)
table(a)/n
table(a)
average(a)
mean(a)
hist(rnorm(1000,mean=70,sd=30))
sample(1:10)
sample(1:10,size=5)
sample(1:10,size=5,replace=TRUE)
sample(c(0,1))
sample(c(0,1),2)
sample(c(0,1),2)
sample(c(0,1),3)
sample(c(0,1),5,replace=TRUE)
sample.int(20,12)
?sample.int
sample(10,5,replace=TRUE)
replace=TRUE
sample(10,5,replace=TRUE)
sample(10,5,replace=TRUE)
sample(5,5,replace=TRUE)
sample(5,5,replace=TRUE)
sample(5,5)
sample(5,5)
sample(5,6)
fair_coin =sample(coins,size=100,replace=TRUE)
coins = c("heads","tails")
fair_coin =sample(coins,size=100,replace=TRUE)
fair_coin
table(fair_coin)
barplot(table(fair_coin))
table(dice)
dice = sample(6,size=100,replace=TRUE)
table(dice)
barplot(table(dice))
dice = sample(6,size=100,replace=TRUE,prob=c(0.1,0.1,0.1,0.1,0.1,0.5))
table(dice)
barplot(table(dice))
set.seed(100)
rnorm(10,mean=3,sd=10)
rnorm(10,mean=3,sd=10)
set.seed(100)
rnorm(10,mean=3,sd=10)
set.seed(100)
rnorm(10,mean=3,sd=10)
set.seed(100)
rnorm(10,mean=3,sd=10)
names(ames)
load("C:/R/r.data/ames.RData")
names(ames)
View(ames)
str(ames)
area = ames$Gr.Liv.Area
hist(area)
shapiro.test(area)
?shapiro.test
sample_means10 =rep(NA,5)
sample_means10
a=c()
a
c(a,1)
c(a,2)
c(a,2,3)
c[0]
array = c(a,2,3)
array
array[1]
?c
csv.read('test.csv')
data = read.csv("test.csv",header=TRUE)
View(data)
data = read.txt("test.txt",header=TRUE)
data = read("test.txt",header=TRUE)
?read
?read.text
test <- read.table("C:/R/r.data/test.txt", header=TRUE, quote="\"")
View(test)
data = read.csv("test.csv",header=TRUE)
data = read.csv("test.csv",header=TRUE)
View(data)
data = read.csv("test.csv",header=TRUE)
View(data)
table(data$A,data$B)
data$A
barplot(data$A,data$B)
countA=sum(data$A:data$AF)
effect = data[,"A":"AF"]
effect = data[,A:AF]
effect = data[,c(A:AF)]
effect = data[,4:34]
View(effect)
sum(effect)
apply(effect,sum)
?apply
apply(effect,1:34,sum)
apply(effect,2,sum)
colsum = apply(effect,2,sum)
barplot(colsum)
boxplot(data$score,data$skin)
boxplot(data$score~data$skin)
boxplot(data$AF~data$skin)
?boxplot
install.packages("e1071")
library(e1071)
dataset = data[3:39]
View(dataset)
fit2 = svm(AF ~ ., data = dataset)
fit2 = svm(AF ~ age+skin, data = dataset)
fit2 = svm(AF ~ Age+skin, data = dataset)
plot(fit2, margin =0.1)
text(fit2)
plot(fit2, margin =0.1)
plot(fit2, margin =0.1)
text(fit2)
fit = rpart(AF ~ skin + Age, data = dataset)
plot(fit, margin =0.1)
text(fit)
library("rpart", lib.loc="C:/R/R-3.1.2/library")
fit = rpart(AF ~ skin + Age, data = dataset)
plot(fit, margin =0.1)
text(fit)
fit = rpart(AF ~ skin + Age + A, data = dataset)
plot(fit, margin =0.1)
text(fit)
dataset=read.csv('test.csv')
View(dataset)
fit = rpart(Score ~ skin + Age + A + B + C + D, data = dataset)
plot(fit, margin =0.1)
text(fit)
fit = rpart(Score ~ skin + Age + A + B + C + D + E, data = dataset)
plot(fit, margin =0.1)
text(fit)
install.arules
detach("package:rpart", unload=TRUE)
install.packages("arules")
library.arules
library(arules)
library(e1071)
library("e1071", lib.loc="C:/R/R-3.1.2/library")
View(dataset)
result = svm(Score~.,data=dataset)
result = svm(Score~Age+skin,data=dataset)
plot(result)
print result
print(result)
summary(result)
data2 = dataset[2:39]
test = as(data2, "transactions")
View(data2)
test = as.factor(data2,"transactions")
data2 = as.factor(data2)
data2 = as.matrix(data2)
data2 = as(data2,'transactions')
data2 = as.factor(data2)
class(data2)
test = as(data2, "transactions")
rules = apriori(data2,parameter = list(supp = 0.2, conf = 0.6, target = "rules"))
rules = apriori(data2,parameter = list(supp = 0.2, conf = 0.6, target = "rules"))
x = c(1:10)
z = length(x)       # null vector
x
z
z[x<5] = 'A'        # x<5 output:true,true,tur,true,false,false.....fale
x = c(1:10)
z = length(x)       # null vector
x<5
z[x<5]
x = c(1:10)
z = length(x)       # null vector
x<5
x
z[x<5]
z[x>=5 & x<8]
z[x>=8]
z[x<5] = 'A'        # x<5 output:true,true,tur,true,false,false.....fale
z[x>=5 & x<8]= 'B'
z[x>=8]= 'c'
z                   # output:A A A A B B B C C C
cbind(x,z)
a = matrix(1:18,nrow=6)
colnames(a)=c('col_1','col_2','col_3')
test = subset(a,select=c(col_1,col_3),subset=(a[2,]>9))
a
test
a[2,]
?matrix
a = matrix(1:18,nrow=6)
a
a[,1]
1[1,]
a[1,]
a[1,]
a[,2]
a[2,]
a[,2]
a = matrix(1:18,nrow=6)
colnames(a)=c('col_1','col_2','col_3')
test = subset(a,select=c(col_1,col_3),subset=(a[2,]>9))
a
test
a[2,]>9
test = subset(a,select=c(col_1,col_3),subset=(a[,2]>9))
a
test
colnames(a)=c('id','年資','年齡')
a
test = subset(a,select=c(id,年齡),subset=(a[,2]>9))
test
test = subset(a,select=c(id,年齡),subset=(年齡>9))
test = subset(a,select=c(id,年齡),subset=('年齡'>9))
test
subset(a,select=c(id,年齡),subset=(a[2,]>9))
subset(a,select=c(id,年齡),subset=(a[,2]>9))
a = matrix(1:18,nrow=6)
colnames(a)=c('id','年資','年齡')
View(a)
a = matrix(1:18,nrow=6)
colnames(a)=c('ID','Num','Age')
View(a)
test = subset(a,select=c(ID,Age),subset=(a[,2]>9))
a
test
test = subset(a,subset=(a[,2]>9))
test
subset(a,subset=(a[,2]>9)
)
z = length(a)         # create null vector
z[a[,3]<15] = 'A'          # x<5 output:true,true,tur,true,false,false.....fale
z[a[,3]>=15 & a[,3]<18]= 'B'
z[a[,3]>=18]= 'C'
z                   # output:A A A A B B B C C C
cbind(a,z)
a[,3]<15
deg = length(a)         # create null vector
deg[a[,3]<15] = 'A'          # x<5 output:true,true,tur,true,false,false.....fale
deg[a[,3]>=15 & a[,3]<18]= 'B'
deg[a[,3]>=18]= 'C'
deg                   # output:A A A A B B B C C C
cbind(a,deg)
a[,3]<15
deg[a[,3]<15]
deg = length(a)         # create null vector
deg[a[,3]<15]
load("C:/R/project/result/finaldata/result_total.txt")
result = read.table('C:/R/project/result/finaldata/result_total.txt',sep=',',header = TRUE)
eff = names(result[,7:65]) #取得result table 7~65欄的欄位名稱(A,B...,BG)
wordCount= with(result,aggregate(result[,eff], by = list(protype,proid,skintype,age_deg),FUN=sum)) #對產品類型,產品id,膚質,年齡層做分群後各項效果詞頻加總 (ex:油性膚質24歲以下對產品id 1234的各項效果詞頻加總)
colnames(wordCount)[1:4]=c('protype','proid','skintype','age_deg')
wordCount[c("item1","item2","item3","item4","item5")] = 0
wordCount$item1 = wordCount$A/(wordCount$A+wordCount$AE)*100
wordCount$item2 = wordCount$E/(wordCount$E+wordCount$AG)*100
wordCount$item3 = wordCount$C/(wordCount$C+wordCount$BF)*100
wordCount$item4 = wordCount$S/(wordCount$S+wordCount$AO)*100
wordCount$item5 = (wordCount$H+wordCount$L+wordCount$X+wordCount$I+wordCount$B)/(wordCount$H+wordCount$L+wordCount$X+wordCount$I+wordCount$B+wordCount$AJ+wordCount$AL+wordCount$AP+wordCount$AK+wordCount$AF)*100
wordCount[is.na(wordCount)] = 0
radarout=wordCount[c('protype','proid','skintype','age_deg','item1','item2','item3','item4','item5')]
colnames(radarout)[5:9]=c('保濕','價格','回購','氣味','舒適度')
test = subset(radarout,subset=(skintype=='E'&age_deg=='O'&(proid==69750|proid==10577|proid==13052)))
par(mar=c(1, 2, 2, 1)) #decrease default margin
layout(matrix(1:4, ncol=2)) #draw 4 plots to device
lapply(1:3, function(i) {
radarchart(rbind(rep(100,3), rep(0,3), test[i,5:9]),title=test[i,2],vlcex=0.9,pfcol='blue')
})
library("fmsb")
install.packages("fmsb")
library("fmsb")
lapply(1:3, function(i) {
radarchart(rbind(rep(100,3), rep(0,3), test[i,5:9]),title=test[i,2],vlcex=0.9,pfcol='blue')
})
load("C:/R/project/Rdata/effset.Rda")
best.mtry=8
best.ntree=500
product = subset(effset,subset=((protype==4) & skintype=='C'))   #篩選自己要的條件
for(i in c(7:66)){
product[,i] = as.factor(product[,i])
}
rf.tr = randomForest(product.tr[,c(7:65)],product.tr[,'rebuy'], ntree = best.ntree, mtry = best.mtry,importance=TRUE)
library(randomForest)
install.packages("randomForest")
library(randomForest)
rf.tr = randomForest(product.tr[,c(7:65)],product.tr[,'rebuy'], ntree = best.ntree, mtry = best.mtry,importance=TRUE)
for(i in c(7:66)){
product[,i] = as.factor(product[,i])
}
ind = sample(2, nrow(product), replace = TRUE, prob=c(0.8, 0.2))
product.tr = product[ind == 1,]     #training set 訓練集
product.te = product[ind == 2,]     #testing  set 測試集
rf.tr = randomForest(product.tr[,c(7:65)],product.tr[,'rebuy'], ntree = best.ntree, mtry = best.mtry,importance=TRUE)
rf.tr$confusion
rf.tr$confusion[,1:2]
table.rf.tr = rf.tr$confusion[,1:2]
sum(table.rf.tr)
rf.tr$confusion
rf.tr$importance
varImpPlot(rf.tr,cex=0.7)   #最有影響的效果,越上方對評分越有影響
print(rf.tr)
pre.test = predict(rf.tr, product.te)
table.test = table(product.te$rebuy,pre.test)
sum(diag(table.test))/sum(table.test)    #testing set預測正確率
rf.te = randomForest(product.te[,c(7:65)],product.te[,'rebuy'], ntree = 500, mtry = 8)
te = as.data.frame((1-rf.te$err.rate[,1])*100)
colnames(te)='rate'
rowcol=c(1:500)
test = cbind(rowcol,te)
plot((1-rf.tr$err.rate[,1])*100,type='l',xlab='no. of trees',ylab='%correct',ylim = c(73,82),col=4)
lines(test$rowcol,test$rate,type='l',col=2)
legend("bottomright", c('Training set','Testing set'), ncol = 1, col=c(4,2), lty = c(1,1))
?with
?aggregate
?with
result = read.table('D:/eff.csv',sep=',',header = TRUE)
View(result)
result = read.table('D:/eff.csv',sep=',',header = TRUE)
View(result)
View(result)
grep("expensive", colnames(data))
grep("smell.good", colnames(data))
grep("proid", colnames(data))
data = read.table('D:/eff.csv',sep=',',header = TRUE)
View(data)
col.names(data)
colnames(data)
grep("A", colnames(data))
data = read.table('D:/eff.csv',sep=',',header = TRUE)
colnames(data)
grep("expensive", colnames(data))
View(data)
grep("smell_good", colnames(data))
?aggregate
wordCount= with(data,aggregate(data[,grep("expensive", colnames(data)):grep("smell_good", colnames(data))], by = list(protype,proid,skintype,age_deg),FUN=sum))
data[,grep("expensive", colnames(data)):grep("smell_good", colnames(data))]
wordCount= with(data,aggregate(data[,grep("expensive", colnames(data)):grep("smell_good", colnames(data))], by = list(proid,skintype,age_deg),FUN=sum))
View(wordCount)
wordCount
?grep
grep("expensive", colnames(data))
grep("smell_good", colnames(data))
aggregate(data[,grep("expensive", colnames(data)):grep("smell_good", colnames(data))], by = list(proid,skintype,age_deg),FUN=sum)
aggregate(data[,grep("expensive", colnames(data)):grep("smell_good", colnames(data))], by = list(proid,skintype,age_deg),FUN=sum)
?with
a = matrix( 1:18 , nrow=6 )
colnames(a) = c( 'ID' , 'Num' , 'Age' )
b = as.data.frame(a)
View(a)
View(b)
a = matrix( 1:18 , nrow=6 )
b = as.data.frame(a)
View(a)
View(b)
a = c(1:10)
a
b = as.data.frame(a)
View(b)
vector = c(1:10)
vector
df = as.data.frame(vector)
df
a
a = matrix( 1:18 , nrow=6 )
colnames(a) = c( 'ID' , 'Num' , 'Age' )
a
a$ID
a$'ID'
b = as.data.frame(a)
b$ID
a = matrix( 1:18 , nrow=6 )
colnames(a) = c( 'ID' , 'Num' , 'Age' )
a$ID
View(a)
b = as.data.frame(a)
rm(b)
rm(a)
a
a = matrix( 1:18 , nrow=6 )
best.mtry
rm(best.mtry)
best.mtry
df$ID
a = matrix( 1:18 , nrow=6 )
colnames(a) = c( 'ID' , 'Num' , 'Age' )
df = as.data.frame(a)
df$ID
plot(runif(100), type="l")
demo(graphics)
library(Rcmdr)
library(ggmap)
install.packages("ggmap")
library(ggmap)
map.taiwan <- get_map(location="Taiwan", zoom=8)
ggmap(map.taiwan)
rm(a)
?with
income_mat = read.table('D:/income.csv',sep=',',header = TRUE)
View(income_mat)
income_mat = read.table('D:/income.csv',sep=',',header = TRUE)
View(income_mat)
income_avg= with(income_mat,aggregate(income_mat[,4], by = list(city,gender),FUN=mean))
income_mat = read.table('D:/income.csv',sep=',',header = TRUE)
income_avg= with(income_mat,aggregate(income_mat[,4], by = list(city,gender),FUN=mean))
View(income_mat)
View(income_avg)
income_avg= with(income_mat,aggregate(income_mat[,4], by = list(gender,city),FUN=mean))
View(income_avg)
aggregate(income_mat[,4], by = list(gender,city),FUN=mean)
aggregate(income_mat[,4], by = list(gender,city),FUN=mean)
describeBy(income_mat$income)
library("psych")
describeBy(income_mat$income)
des.mat = describeBy(income_mat$income)
View(des.mat)
des.mat = describeBy(income_mat$income,income$city)
des.mat = describeBy(income_mat$income,income_mat$city,mat=TRUE)
View(des.mat)
income_avg
?psych
des.mat
View(des.mat)
?merge
emp = read.table('D:/employee.csv',sep=',',header = TRUE)
dep = read.table('D:/department.csv',sep=',',header = TRUE)
emp = read.table('D:/employee.csv',sep=',',header = TRUE)
dep = read.table('D:/department.csv',sep=',',header = TRUE)
View(dep)
View(emp)
merge(emp,dep)
?merge
merge(emp,dep,by='department')
dep2 = read.table('D:/department2.csv',sep=',',header = TRUE)
merge(emp,dep2,by.x=’department’,by.y=’dep’)
View(emp)
View(dep2)
merge(emp,dep2, by.x= 'department', by.y='dep')
describeBy(income_mat$income,income_mat$city,mat=TRUE)
income_mat = read.table('D:/income.csv',sep=',',header = TRUE)
income_avg= with(income_mat,aggregate(income_mat[,4], by = list(city,gender),FUN=mean))
describeBy(income_mat$income,income_mat$city,mat=TRUE)
library(nutshell)
install.packages("nutshell")
mid.term <- matrix(c(60,80,65,85,80,90,99), nrow=7, ncol=1, byrow=FALSE,   dimnames = list(c(),c("mid.term")))
View(mid.term)
mid.term <- matrix(c(60,80,65,85,80,90,99), nrow=7, ncol=1, byrow=FALSE,   dimnames = list(c(),c("mid.term")))
mid.term
mid.term <- matrix(c(60,80,65,85,80,90,99), nrow=7, ncol=1, byrow=FALSE,   dimnames = list(c(),c("mid.term")))
View(mid.term)
mid.term
data.ts <- ts(c(2,5,4,6,3,7,9:8),start=c(2009,2),frequency=4)
data.ts
is.ts(data.ts)
start(data.ts)
end(data.ts)
frequency(data.ts)
deltat(data.ts) # 0.25(=1/4)
plot(data.ts, type="b")
?ts
data.ts <- ts(c(2,5,4,6,3,7,9:8),start=c(2009,2),frequency=4)
plot(data.ts, type="b")
data.ts
data.ts <- ts(c(2,5,4,6,3,7,9:8),start=c(2009,2),frequency=5)
data.ts
data.ts <- ts(c(2,5,4,6,3,7,9:8),start=c(2009,2),frequency=3)
data.ts
data.ts <- ts(c(2,5,4,6,3,7,9:8),start=c(2009,2),frequency=4)
data.ts
data.ts <- ts(c(2,5,4,6,3,7,9,8),start=c(2009,2),frequency=4)
data.ts
data.ts <- ts(c(1:32),start=c(2009,2),frequency=12)
data.ts
plot(data.ts, type="b")
plot(data.ts, type="b")
deltat(data.ts) # 0.25(=1/4)
